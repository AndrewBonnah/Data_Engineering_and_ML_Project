{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b2c545b",
   "metadata": {},
   "source": [
    "<h1>\n",
    "Stock ML Scraping, Cleaning, and Analysis\n",
    "</h1>\n",
    "\n",
    "<p>\n",
    "This project is intended to be a body of work showing my ability to code and analyze data.\n",
    "\n",
    "No AI tools were used.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a329a46e",
   "metadata": {},
   "source": [
    "The architecture I am planning is:\n",
    "\n",
    "yfinance (scrape most active tickers) -> Google Finance (get basic financial info) -> 12api (get stock price for a certain period)\n",
    "\n",
    "Put these together into data to be analyzed with ML to try and define a strategy to \"beat\" the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68d8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NVDA', 'SNAP', 'NIO', 'PLUG', 'INTC', 'CADE', 'ONDS', 'KVUE', 'PLTR', 'GOOGL', 'SOFI', 'HIMS', 'F', 'CFLT', 'MARA', 'TSLA', 'OWL', 'AMZN', 'AMD', 'GRAB', 'BMNR', 'PFE', 'OPEN', 'SMCI', 'NVO', 'ABEV', 'NU', 'BBD', 'IREN', 'NFLX', 'ACHR', 'GOOG', 'HOOD', 'VALE', 'MSFT', 'DNN', 'MSTR', 'CPNG', 'AAPL', 'CIFR', 'BTG', 'PYPL', 'MU', 'CCC', 'AVGO', 'DAY', 'WULF', 'GGB', 'AAL', 'CLSK', 'RIG', 'ORCL', 'BSX', 'UBER', 'ITUB', 'QBTS', 'EOSE', 'JOBY', 'RGTI', 'VZ', 'SAN', 'T', 'SOUN', 'PSLV', 'NOW', 'CDE', 'SNDK', 'PATH', 'BAC', 'QCOM', 'APLD', 'RIOT', 'HBAN', 'ADT', 'SIRI', 'IONQ', 'COIN', 'WMT', 'NGD', 'BTE', 'B', 'HL', 'ARM', 'RIVN', 'SMR', 'NOK', 'AG', 'SLB', 'WBD', 'CRWV', 'CMCSA', 'HPQ', 'LUMN', 'VOD', 'RKLB', 'FLNC', 'USAR', 'AUR', 'BMY', 'HPE', 'TTD', 'RKT', 'JBLU', 'PTEN', 'U', 'PBR', 'MRK', 'CRM', 'CARR', 'FCX', 'EL', 'PCH', 'KO', 'CSCO', 'IBRX', 'LYG', 'QS', 'ASTS', 'PHYS', 'SHOP', 'CMG', 'RBLX', 'APH', 'TOST', 'NBIS', 'C', 'CCL', 'MRVL', 'STLA', 'FIG', 'TSM', 'META', 'BULL', 'KGC', 'ASX', 'UWMC', 'AGNC', 'EXK', 'CWAN', 'NCLH', 'DOW', 'UUUU', 'XOM', 'CIG', 'KKR', 'ET', 'RF', 'CORZ', 'CNH', 'KEY', 'ARCC', 'PCG', 'CRCL', 'GLXY', 'LYFT', 'NEM', 'COHR', 'BE', 'GSK', 'DVN', 'EQX', 'DKNG', 'UAA', 'PAAS', 'PG', 'ABT', 'SHEL', 'CCI', 'BP', 'CLF', 'FSM', 'AXL', 'OBDC', 'HUT', 'COTY', 'UNH', 'KHC', 'ENPH', 'CX', 'BX', 'VLY', 'LUNR', 'CSX', 'OKLO', 'WFC', 'PL', 'INFY', 'VG', 'ZETA', 'WDC', 'NKE', 'PBR-A', 'SBSW', 'MRNA', 'GME', 'TEVA', 'HLN', 'RELX', 'PINS', 'BABA', 'COMP', 'BAX', 'HAL', 'FITB', 'CNQ', 'JD', 'BCS', 'CTRA', 'UEC', 'NOV', 'WIT', 'IP', 'MDLZ', 'FAST', 'WU', 'AFRM', 'OXY', 'TMC', 'PANW', 'CMA', 'CAG', 'FTNT', 'KMI', 'LRCX', 'CVE', 'ORLY', 'SVM', 'RAL', 'PR', 'TENB', 'BKR', 'RITM', 'TME', 'TPG', 'USB', 'ABBV', 'PEP', 'TEM', 'DELL', 'S', 'DIS', 'GLW', 'AES', 'XPEV', 'TXN', 'VRNS', 'MPW', 'MO', 'DOC', 'XYZ', 'ARES', 'OS', 'NEE', 'SM', 'ANET', 'SONY', 'CVX', 'CRDO', 'MGM', 'SID', 'ON', 'JNJ', 'AVTR', 'AMCR', 'COP', 'IBKR', 'NXE', 'CNC', 'UMC', 'RBRK', 'APP', 'LITE', 'MDT', 'ERIC', 'IOT', 'MP', 'CL', 'TRI', 'RIO', 'BCE', 'DT', 'TGB', 'V', 'SNOW', 'RDDT', 'RUN', 'LCID', 'WBS', 'VST', 'MBLY', 'JPM', 'AA', 'XEL', 'CVS', 'CIVI', 'HBM', 'DASH']\n"
     ]
    }
   ],
   "source": [
    "# first step scrape yfinance for later ingesting with stock class.\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def get_yfinance_tickers():\n",
    "    \"\"\"\n",
    "    input: None\n",
    "    output: returns tickers of most active stocks, stops collecting when yfinance runs out (1-3 loops)\n",
    "    \"\"\"\n",
    "    # list to hold data\n",
    "    tickers = []\n",
    "\n",
    "    # default starting index for 100 is ?start=0&count=100\n",
    "    start_ind = 0\n",
    "    count = 100\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    #header for request\n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        #base URL (needs to change every loop)\n",
    "        url = f\"https://finance.yahoo.com/markets/stocks/most-active/?start={start_ind}&count={count}\"\n",
    "        # stop on error, call soup\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        # grab main container\n",
    "        container = soup.select_one(\"div.container.yf-1bczin\")\n",
    "\n",
    "        # if not main container stop\n",
    "        if not container:\n",
    "            break\n",
    "\n",
    "\n",
    "        # if no more data stop\n",
    "        if container.select_one(\"div.no-data\"):\n",
    "            break\n",
    "\n",
    "        links = soup.find_all(\"a\", {\"data-testid\": \"table-cell-ticker\"})\n",
    "\n",
    "        \n",
    "        for link in links:\n",
    "            href = link.get(\"href\")\n",
    "\n",
    "            # These are the link extensions to go to individual pages, \n",
    "            # in format /quote/SNAP/, which would be accessed like\n",
    "            # https://finance.yahoo.com/quote/MU/\n",
    "            # instead of drilling TWO levels deeper using BS4,\n",
    "            # which is a buggy and annoying process,\n",
    "            # the best practice I've found is to use RegEx.\n",
    "            #\n",
    "            # RegEx reduces time and memory complexity\n",
    "            # by skpping over redundant soup layering.\n",
    "            #\n",
    "            # I am opting to use regex to remove the chars:\n",
    "            #   /quote/ /\n",
    "\n",
    "            match = re.search(r\"/quote/([A-Z0-9.-]+)\", href)\n",
    "            if match:\n",
    "                cleaned_title = match.group(1)\n",
    "                tickers.append(cleaned_title)\n",
    "        time.sleep(2)\n",
    "\n",
    "        start_ind += 100\n",
    "\n",
    "    return tickers\n",
    "\n",
    "tickers = get_yfinance_tickers()\n",
    "print(tickers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ac719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next up one by one we are going to assemble a dictionary that has key's stocks, and google finance\n",
    "# info as a nested dictionary of information.\n",
    "\n",
    "def get_google_info_w_yfin_tickers(list_of_tickers):\n",
    "    \"\"\"\n",
    "    input: List of tickers\n",
    "    output: returns dictionary of dictionary of tickers and info.\n",
    "    in the format of {'F':{'q1_2025_profit':100000, market_cap, etc.}}\n",
    "    \"\"\"\n",
    "    #header for request, in the future state this can be a class var\n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
